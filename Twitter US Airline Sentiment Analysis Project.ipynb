{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Tweets Analysis as positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = pd.read_csv('0000000000002747_test_twitter_x_test (1).csv')\n",
    "training_data= pd.read_csv('0000000000002747_training_twitter_x_y_train (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_id', 'airline_sentiment', 'airline', 'airline_sentiment_gold',\n",
      "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
      "       'tweet_created', 'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n",
      "Index(['tweet_id', 'airline', 'airline_sentiment_gold', 'name',\n",
      "       'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
      "       'tweet_created', 'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(training_data.columns)\n",
    "print(testing_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_result = training_data['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>569677636613439488</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bobgiolito</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Why did you load us in this flying sar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 17:58:27 -0800</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>569658903044218880</td>\n",
       "      <td>negative</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aaronkinnari</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue that is a stock response. Delays not ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 16:44:00 -0800</td>\n",
       "      <td>Gotham</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>568542766860541952</td>\n",
       "      <td>positive</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TimothySays</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue That'd be nice! Hoping to rack up eno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 14:48:53 -0800</td>\n",
       "      <td>Burlington, MA</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>570116209263427584</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lindaSWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@united frankly worse customer service ever. P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 23:01:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>568870144891600896</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amyums</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir yeah haha. Never been in one. It...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 12:29:46 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment    airline airline_sentiment_gold  \\\n",
       "0  567900433542488064          negative  Southwest                    NaN   \n",
       "1  569989168903819264          positive  Southwest                    NaN   \n",
       "2  568089179520954368          positive     United                    NaN   \n",
       "3  568928195581513728          negative  Southwest                    NaN   \n",
       "4  568594180014014464          negative     United                    NaN   \n",
       "5  569677636613439488          negative     United                    NaN   \n",
       "6  569658903044218880          negative      Delta                    NaN   \n",
       "7  568542766860541952          positive      Delta                    NaN   \n",
       "8  570116209263427584          negative     United                    NaN   \n",
       "9  568870144891600896          positive  Southwest                    NaN   \n",
       "\n",
       "            name negativereason_gold  retweet_count  \\\n",
       "0  ColeyGirouard                 NaN              0   \n",
       "1  WalterFaddoul                 NaN              0   \n",
       "2      LocalKyle                 NaN              0   \n",
       "3    amccarthy19                 NaN              0   \n",
       "4        J_Okayy                 NaN              0   \n",
       "5     bobgiolito                 NaN              0   \n",
       "6   aaronkinnari                 NaN              0   \n",
       "7    TimothySays                 NaN              0   \n",
       "8       lindaSWC                 NaN              1   \n",
       "9         amyums                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @SouthwestAir I am scheduled for the morning, ...         NaN   \n",
       "1  @SouthwestAir seeing your workers time in and ...         NaN   \n",
       "2  @united Flew ORD to Miami and back and  had gr...         NaN   \n",
       "3     @SouthwestAir @dultch97 that's horse radish üò§üê¥         NaN   \n",
       "4  @united so our flight into ORD was delayed bec...         NaN   \n",
       "5  @united Why did you load us in this flying sar...         NaN   \n",
       "6  @JetBlue that is a stock response. Delays not ...         NaN   \n",
       "7  @JetBlue That'd be nice! Hoping to rack up eno...         NaN   \n",
       "8  @united frankly worse customer service ever. P...         NaN   \n",
       "9  @SouthwestAir yeah haha. Never been in one. It...         NaN   \n",
       "\n",
       "               tweet_created              tweet_location  \\\n",
       "0  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3  2015-02-20 16:20:26 -0800                         NaN   \n",
       "4  2015-02-19 18:13:11 -0800                         NaN   \n",
       "5  2015-02-22 17:58:27 -0800             Los Angeles, CA   \n",
       "6  2015-02-22 16:44:00 -0800                      Gotham   \n",
       "7  2015-02-19 14:48:53 -0800              Burlington, MA   \n",
       "8  2015-02-23 23:01:11 -0800                         NaN   \n",
       "9  2015-02-20 12:29:46 -0800                         NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0      Atlantic Time (Canada)  \n",
       "1  Central Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3      Atlantic Time (Canada)  \n",
       "4  Eastern Time (US & Canada)  \n",
       "5  Pacific Time (US & Canada)  \n",
       "6                       Quito  \n",
       "7  Eastern Time (US & Canada)  \n",
       "8                         NaN  \n",
       "9  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_data(data):\n",
    "    del data['tweet_id']\n",
    "    del data['name']\n",
    "    del data['tweet_created']\n",
    "    del data['tweet_location']\n",
    "    del data['user_timezone']\n",
    "    del data['tweet_coord']\n",
    "    del data['airline_sentiment']\n",
    "    del data['airline']\n",
    "    del data['negativereason_gold']\n",
    "    del data['retweet_count']\n",
    "    del data['airline_sentiment_gold']\n",
    "    return data\n",
    "\n",
    "def updated_data1(data):\n",
    "    del data['tweet_id']\n",
    "    del data['name']\n",
    "    del data['tweet_created']\n",
    "    del data['tweet_location']\n",
    "    del data['user_timezone']\n",
    "    del data['tweet_coord']\n",
    "    del data['airline']\n",
    "    del data['negativereason_gold']\n",
    "    del data['retweet_count']\n",
    "    del data['airline_sentiment_gold']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = updated_data(training_data)\n",
    "testing_data = updated_data1(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AmericanAir after all, the plane didn‚Äôt land ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@united we have developers flying down tmrw mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@USAirways hello??? Anyone there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@USAirways @husainhaqqani Mr. Husain u shld pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@USAirways not likely, flightaware says plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@AmericanAir they don't even give an option to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @AmericanAir In car gng to DFW. Pulled over 1h...\n",
       "1  @AmericanAir after all, the plane didn‚Äôt land ...\n",
       "2  @SouthwestAir can't believe how many paying cu...\n",
       "3  @USAirways I can legitimately say that I would...\n",
       "4  @AmericanAir still no response from AA. great ...\n",
       "5  @united we have developers flying down tmrw mo...\n",
       "6                  @USAirways hello??? Anyone there?\n",
       "7  @USAirways @husainhaqqani Mr. Husain u shld pr...\n",
       "8  @USAirways not likely, flightaware says plane ...\n",
       "9  @AmericanAir they don't even give an option to..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Stop words and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimpleTag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanWords(words):\n",
    "    words = word_tokenize(words)\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stops:\n",
    "            #w1 = lemmatizer.lemmatize(w.lower())\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = getSimpleTag(pos[0][1]))\n",
    "            output_words.append(clean_word)      \n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled\n",
      "@SouthwestAir seeing your workers time in and time out going above and beyond is why I love flying with you guys. Thank you!\n",
      "@united Flew ORD to Miami and back and  had great crew, service on both legs. THANKS\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for doc in training_data['text']:\n",
    "    print(doc)\n",
    "    if i == 2:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_arr = [cleanWords(doc) for doc in training_data['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pre computed saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open('words_arr.txt', 'wb')\n",
    "pickle.dump(words_arr, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open('words_arr.txt', 'rb')\n",
    "words_arr = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SouthwestAir',\n",
       "  'schedule',\n",
       "  'morning',\n",
       "  '2',\n",
       "  'days',\n",
       "  'fact',\n",
       "  'yes..not',\n",
       "  'sure',\n",
       "  'even',\n",
       "  'flight',\n",
       "  'one',\n",
       "  'Cancelled',\n",
       "  'Flightled'],\n",
       " ['SouthwestAir',\n",
       "  'see',\n",
       "  'workers',\n",
       "  'time',\n",
       "  'time',\n",
       "  'go',\n",
       "  'beyond',\n",
       "  'love',\n",
       "  'fly',\n",
       "  'guys',\n",
       "  'Thank'],\n",
       " ['united',\n",
       "  'Flew',\n",
       "  'ORD',\n",
       "  'Miami',\n",
       "  'back',\n",
       "  'great',\n",
       "  'crew',\n",
       "  'service',\n",
       "  'legs',\n",
       "  'THANKS'],\n",
       " ['SouthwestAir', 'dultch97', \"'s\", 'horse', 'radish', 'üò§üê¥'],\n",
       " ['united',\n",
       "  'flight',\n",
       "  'ORD',\n",
       "  'delayed',\n",
       "  'Air',\n",
       "  'Force',\n",
       "  'One',\n",
       "  'last',\n",
       "  'flight',\n",
       "  'SBN',\n",
       "  '8:20',\n",
       "  '5',\n",
       "  'mins',\n",
       "  'land'],\n",
       " ['united',\n",
       "  'load',\n",
       "  'u',\n",
       "  'fly',\n",
       "  'sardine',\n",
       "  'knew',\n",
       "  'pilots',\n",
       "  '2',\n",
       "  'hours',\n",
       "  'Late',\n",
       "  'Flight',\n",
       "  'incompetent',\n",
       "  'beyond',\n",
       "  'belief'],\n",
       " ['JetBlue',\n",
       "  'stock',\n",
       "  'response',\n",
       "  'Delays',\n",
       "  'frustrate',\n",
       "  'poor',\n",
       "  'cust',\n",
       "  'serv',\n",
       "  'amp',\n",
       "  'told',\n",
       "  '3',\n",
       "  'ppl',\n",
       "  'wait',\n",
       "  'amp',\n",
       "  \"'d\",\n",
       "  'come',\n",
       "  'back'],\n",
       " ['JetBlue',\n",
       "  \"'d\",\n",
       "  'nice',\n",
       "  'Hoping',\n",
       "  'rack',\n",
       "  'enough',\n",
       "  'miles',\n",
       "  'take',\n",
       "  'trip',\n",
       "  'Seattle',\n",
       "  'enjoy',\n",
       "  'perfect',\n",
       "  'latte',\n",
       "  'city',\n",
       "  'coffee'],\n",
       " ['united',\n",
       "  'frankly',\n",
       "  'bad',\n",
       "  'customer',\n",
       "  'service',\n",
       "  'ever',\n",
       "  'Problems',\n",
       "  'happen',\n",
       "  'deal',\n",
       "  'defines',\n",
       "  'company',\n",
       "  'Never',\n",
       "  'United'],\n",
       " ['SouthwestAir',\n",
       "  'yeah',\n",
       "  'haha',\n",
       "  'Never',\n",
       "  'one',\n",
       "  \"'s\",\n",
       "  'expensive',\n",
       "  'üòÇüòÇ',\n",
       "  'much',\n",
       "  'fun',\n",
       "  'destinationdragons'],\n",
       " ['SouthwestAir',\n",
       "  'MCO-',\n",
       "  'gt',\n",
       "  'DCA',\n",
       "  'flight',\n",
       "  'almost',\n",
       "  'full',\n",
       "  'people',\n",
       "  'screw',\n",
       "  'MSY-DCA',\n",
       "  'Cancelled',\n",
       "  'Flightation',\n",
       "  'united',\n",
       "  'USAirways',\n",
       "  \"n't\",\n",
       "  'Cancelled',\n",
       "  'Flight',\n",
       "  'SWA=mistake']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_arr[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = []\n",
    "i = 0\n",
    "for doc in words_arr:\n",
    "    stemmed_words.append([])\n",
    "    for w in doc:\n",
    "        stemmed_words[i].append(ps.stem(w))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SouthwestAir',\n",
       "  'schedule',\n",
       "  'morning',\n",
       "  '2',\n",
       "  'days',\n",
       "  'fact',\n",
       "  'yes..not',\n",
       "  'sure',\n",
       "  'even',\n",
       "  'flight',\n",
       "  'one',\n",
       "  'Cancelled',\n",
       "  'Flightled'],\n",
       " ['SouthwestAir',\n",
       "  'see',\n",
       "  'workers',\n",
       "  'time',\n",
       "  'time',\n",
       "  'go',\n",
       "  'beyond',\n",
       "  'love',\n",
       "  'fly',\n",
       "  'guys',\n",
       "  'Thank'],\n",
       " ['united',\n",
       "  'Flew',\n",
       "  'ORD',\n",
       "  'Miami',\n",
       "  'back',\n",
       "  'great',\n",
       "  'crew',\n",
       "  'service',\n",
       "  'legs',\n",
       "  'THANKS'],\n",
       " ['SouthwestAir', 'dultch97', \"'s\", 'horse', 'radish', 'üò§üê¥'],\n",
       " ['united',\n",
       "  'flight',\n",
       "  'ORD',\n",
       "  'delayed',\n",
       "  'Air',\n",
       "  'Force',\n",
       "  'One',\n",
       "  'last',\n",
       "  'flight',\n",
       "  'SBN',\n",
       "  '8:20',\n",
       "  '5',\n",
       "  'mins',\n",
       "  'land'],\n",
       " ['united',\n",
       "  'load',\n",
       "  'u',\n",
       "  'fly',\n",
       "  'sardine',\n",
       "  'knew',\n",
       "  'pilots',\n",
       "  '2',\n",
       "  'hours',\n",
       "  'Late',\n",
       "  'Flight',\n",
       "  'incompetent',\n",
       "  'beyond',\n",
       "  'belief'],\n",
       " ['JetBlue',\n",
       "  'stock',\n",
       "  'response',\n",
       "  'Delays',\n",
       "  'frustrate',\n",
       "  'poor',\n",
       "  'cust',\n",
       "  'serv',\n",
       "  'amp',\n",
       "  'told',\n",
       "  '3',\n",
       "  'ppl',\n",
       "  'wait',\n",
       "  'amp',\n",
       "  \"'d\",\n",
       "  'come',\n",
       "  'back'],\n",
       " ['JetBlue',\n",
       "  \"'d\",\n",
       "  'nice',\n",
       "  'Hoping',\n",
       "  'rack',\n",
       "  'enough',\n",
       "  'miles',\n",
       "  'take',\n",
       "  'trip',\n",
       "  'Seattle',\n",
       "  'enjoy',\n",
       "  'perfect',\n",
       "  'latte',\n",
       "  'city',\n",
       "  'coffee'],\n",
       " ['united',\n",
       "  'frankly',\n",
       "  'bad',\n",
       "  'customer',\n",
       "  'service',\n",
       "  'ever',\n",
       "  'Problems',\n",
       "  'happen',\n",
       "  'deal',\n",
       "  'defines',\n",
       "  'company',\n",
       "  'Never',\n",
       "  'United'],\n",
       " ['SouthwestAir',\n",
       "  'yeah',\n",
       "  'haha',\n",
       "  'Never',\n",
       "  'one',\n",
       "  \"'s\",\n",
       "  'expensive',\n",
       "  'üòÇüòÇ',\n",
       "  'much',\n",
       "  'fun',\n",
       "  'destinationdragons']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for doc in words_arr:\n",
    "    all_words += doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = nltk.FreqDist(all_words)\n",
    "common = freq.most_common(1000)\n",
    "features = [i[0] for i in common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(max_features = 3000, ngram_range = (1, 2))\n",
    "train_data = count_vec.fit_transform(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '00pm', '02', '03', '05', '10', '10 000', '10 24', '10 30']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = count_vec.transform(training_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = count_vec.transform(testing_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x3000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 132295 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x3000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 43572 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10980,), (10980, 3000))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_result.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(train_data, training_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting score from svm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6252276867030966"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(train_data, training_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = svc.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'positive'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('y_pred_svc.csv', y_pred_svc, fmt = \"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 25building tree 2 of 25\n",
      "\n",
      "building tree 3 of 25\n",
      "building tree 4 of 25\n",
      "building tree 5 of 25\n",
      "building tree 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 25\n",
      "building tree 8 of 25\n",
      "building tree 9 of 25\n",
      "building tree 10 of 25\n",
      "building tree 11 of 25\n",
      "building tree 12 of 25\n",
      "building tree 13 of 25\n",
      "building tree 14 of 25\n",
      "building tree 15 of 25\n",
      "building tree 16 of 25\n",
      "building tree 17 of 25\n",
      "building tree 18 of 25\n",
      "building tree 19 of 25\n",
      "building tree 20 of 25\n",
      "building tree 21 of 25\n",
      "building tree 22 of 25\n",
      "building tree 23 of 25\n",
      "building tree 24 of 25\n",
      "building tree 25 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  25 out of  25 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=2,\n",
       "            oob_score=False, random_state=None, verbose=7,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(criterion = 'gini', n_estimators = 25, n_jobs = 2, verbose = 7)\n",
    "rnd_clf.fit(train_data, training_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting score from random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936247723132969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print(rnd_clf.score(train_data, training_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral', 'positive', 'negative'}\n"
     ]
    }
   ],
   "source": [
    "y_pred_rnd = rnd_clf.predict(test_data)\n",
    "print(set(y_pred_rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('y_pred_rnd.csv', y_pred_rnd, fmt = \"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
